{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fbc18d39",
      "metadata": {
        "id": "fbc18d39"
      },
      "source": [
        "This file is used to run the code on Google Colab.\n",
        "The parameters of the Trainer are set to use the GPU A100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "install_deps",
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imports",
        "outputId": "4cef33c0-75bd-4ca4-f707-c70b3d26500f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import csv\n",
        "from functools import partial\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "# Deactivate WandB\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "os.environ[\"WANDB_PROJECT\"] = \"disabled\"\n",
        "\n",
        "# Make sure the notebook uses the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IQy1zPg9AMve",
      "metadata": {
        "id": "IQy1zPg9AMve"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive to save progression\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_ROOT = Path('/content/drive/MyDrive')\n",
        "PROJECT_DIR = DRIVE_ROOT / 'deberta_training'\n",
        "DATA_DIR = PROJECT_DIR / 'data'\n",
        "ARTIFACTS_DIR = PROJECT_DIR / 'artifacts'\n",
        "CHECKPOINT_DIR = ARTIFACTS_DIR / 'checkpoints'\n",
        "BEST_MODEL_DIR = ARTIFACTS_DIR / 'best_model'\n",
        "PREDICTIONS_DIR = ARTIFACTS_DIR / 'predictions'\n",
        "LOGS_DIR = ARTIFACTS_DIR / 'logs'\n",
        "\n",
        "for d in [PROJECT_DIR, DATA_DIR, ARTIFACTS_DIR, CHECKPOINT_DIR, BEST_MODEL_DIR, PREDICTIONS_DIR, LOGS_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('Location on Drive', PROJECT_DIR)\n",
        "print('Place the files tweets_train.csv and tweets_val.csv in:', DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D0jtKJFHuEGc",
      "metadata": {
        "id": "D0jtKJFHuEGc"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load_data",
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "train_path = DATA_DIR / 'tweets_train.csv'\n",
        "val_path = DATA_DIR / 'tweets_val.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "train_set = Dataset.from_pandas(train_df[[\"text\", \"label\"]])\n",
        "val_set = Dataset.from_pandas(val_df[[\"text\", \"label\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u5NV_oQntsuL",
      "metadata": {
        "id": "u5NV_oQntsuL"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tokenize",
      "metadata": {
        "id": "tokenize"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "TOKENIZED_TRAIN_DIR = DATA_DIR / \"train_tokenized\"\n",
        "TOKENIZED_VAL_DIR   = DATA_DIR / \"val_tokenized\"\n",
        "\n",
        "max_length = 128\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\", use_fast=True)\n",
        "\n",
        "tokenize_fct = partial(\n",
        "    tokenizer, truncation=True, max_length=max_length\n",
        ")\n",
        "\n",
        "# Check previous tokenization to fasten\n",
        "if TOKENIZED_TRAIN_DIR.exists() and TOKENIZED_VAL_DIR.exists():\n",
        "    train_tokenized = load_from_disk(TOKENIZED_TRAIN_DIR)\n",
        "    val_tokenized = load_from_disk(TOKENIZED_VAL_DIR)\n",
        "\n",
        "else:\n",
        "    # Tokenize datasets using DeBERTa tokenizer\n",
        "    print(\"Tokenizing datasets for DeBERTa...\\n\")\n",
        "\n",
        "    train_tokenized = train_set.map(\n",
        "        lambda batch: tokenize_fct(batch[\"text\"]), batched=True\n",
        "    )\n",
        "    val_tokenized = val_set.map(\n",
        "        lambda batch: tokenize_fct(batch[\"text\"]), batched=True\n",
        "    )\n",
        "\n",
        "    train_tokenized = train_tokenized.remove_columns([\"text\"])\n",
        "    val_tokenized = val_tokenized.remove_columns([\"text\"])\n",
        "    train_tokenized.set_format(\"torch\")\n",
        "    val_tokenized.set_format(\"torch\")\n",
        "\n",
        "    train_tokenized.save_to_disk(DATA_DIR / \"train_tokenized\")\n",
        "    val_tokenized.save_to_disk(DATA_DIR / \"val_tokenized\")\n",
        "\n",
        "train_tokenized, val_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1qdZ444eAMvf",
      "metadata": {
        "id": "1qdZ444eAMvf"
      },
      "source": [
        "# Metrics Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metrics",
      "metadata": {
        "id": "metrics"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(preds, labels):\n",
        "    return np.mean(labels == preds)\n",
        "\n",
        "def f1_score(preds, labels):\n",
        "    tp = np.sum((labels == 1) & (preds == 1))\n",
        "    fp = np.sum((labels != 1) & (preds == 1))\n",
        "    if tp + fp == 0:\n",
        "        return 0.0\n",
        "    precision = tp / (tp + fp)\n",
        "\n",
        "    tp = np.sum((labels == 1) & (preds == 1))\n",
        "    fn = np.sum((labels == 1) & (preds != 1))\n",
        "    if tp + fn == 0:\n",
        "        return 0.0\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "label2id = {\"NEG\": 0, \"POS\": 1}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_fn(preds, labels),\n",
        "        \"f1\": f1_score(preds, labels),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b2cdDsTAMvf",
      "metadata": {
        "id": "4b2cdDsTAMvf"
      },
      "source": [
        "# DeBERTa Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train",
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=tokenizer,\n",
        "    pad_to_multiple_of=8,\n",
        ")\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "train_tokenized = load_from_disk(DATA_DIR / \"train_tokenized\")\n",
        "val_tokenized = load_from_disk(DATA_DIR / \"val_tokenized\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'microsoft/deberta-v3-large',\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ").to(device)\n",
        "\n",
        "model.config.problem_type = \"single_label_classification\"\n",
        "output_dir = str(CHECKPOINT_DIR)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    eval_strategy='steps',\n",
        "    save_strategy='steps',\n",
        "    eval_steps=10000,\n",
        "    save_steps=20000,\n",
        "    logging_steps=200,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',  # Optimize for accuracy\n",
        "    greater_is_better=True,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=1,\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    bf16=True,                         # Set to True because of Colab\n",
        "    tf32=True,\n",
        "    report_to='none',\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    dataloader_num_workers=4,\n",
        "    dataloader_pin_memory=True,\n",
        "    gradient_accumulation_steps=1,\n",
        "    group_by_length=False,\n",
        "    disable_tqdm=True\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"Starting DeBERTa training...\\n\")\n",
        "if any(CHECKPOINT_DIR.iterdir()):\n",
        "    print(\"Use last checkpoint to restart\")\n",
        "    trainer.train(resume_from_checkpoint=True)\n",
        "else:\n",
        "    print(\"Start from anew\")\n",
        "    trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qZUqk4UtAMvf",
      "metadata": {
        "id": "qZUqk4UtAMvf"
      },
      "source": [
        "# Save best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save_model",
      "metadata": {
        "id": "save_model"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Save best model on the Drive\n",
        "best_model_dir = BEST_MODEL_DIR\n",
        "best_model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "trainer.save_model(str(best_model_dir))\n",
        "tokenizer.save_pretrained(str(best_model_dir))\n",
        "\n",
        "# Download best model\n",
        "files.download(str(best_model_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3fd0e4d",
      "metadata": {},
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00501c19",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_path = DATA_DIR / \"test_data.txt\"\n",
        "\n",
        "tweets = []\n",
        "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    tweets = [line.rstrip(\"\\n\") for line in f if line.strip() != \"\"]\n",
        "\n",
        "indices = np.arange(1, len(tweets)+1)\n",
        "test_dataset = Dataset.from_dict({\"text\": tweets})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c105ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_tokenized = test_dataset.map(lambda batch: tokenize_fct(batch[\"text\"]), batched=True)\n",
        "test_tokenized = test_tokenized.remove_columns([\"text\"])\n",
        "test_tokenized.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae83518f",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    test_tokenized, \n",
        "    batch_size=32, \n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691913d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert 0/1 to -1/1\n",
        "y_pred = 2 * all_preds - 1\n",
        "\n",
        "if not all(i in [-1, 1] for i in y_pred):\n",
        "    raise ValueError(\"y_pred can only contain values -1, 1\")\n",
        "\n",
        "submission = pd.DataFrame({'Id': indices, 'Prediction': y_pred})\n",
        "csv_name = PREDICTIONS_DIR / 'deberta_submission.csv'\n",
        "with open(csv_name, \"w\", newline=\"\") as csvfile:\n",
        "        fieldnames = [\"Id\", \"Prediction\"]\n",
        "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for r1, r2 in zip(indices, y_pred):\n",
        "            writer.writerow({\"Id\": int(r1), \"Prediction\": int(r2)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188a7ea5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download submission file\n",
        "files.download(str(csv_name))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
